
本章旨在通过具体的实践案例，向读者展示如何灵活运用Linux系统的资源限制机制——包括`ulimit`命令、`/etc/security/limits.conf`配置文件以及`pam_limits`模块——来解决实际的系统管理问题。我们将通过真实世界的场景，深入探讨如何通过合理的资源限制配置，有效提升系统的性能、稳定性和安全性。无论是为了防止恶意程序的资源滥用，还是为了优化关键服务的运行效率，本章的案例都将提供宝贵的实践指导。

### 6.1 防止fork炸弹(Fork Bomb)

资源限制在保障系统安全方面的一个典型应用是防御或缓解所谓的“fork炸弹(Fork Bomb)”。fork炸弹是一种特殊类型的拒绝服务攻击(Denial of Service, DoS)，它通过不断地创建新的进程来快速消耗系统的进程资源，直至系统因无法创建新进程而崩溃或变得不可响应。

一个简单的bash脚本形式的fork炸弹可能看起来像这样：
```bash
:(){ :|:& };:

这个看似神秘的命令可以分解理解：  
定义一个函数，函数名为 `:`。  
函数体是 `:{ :|:& };:`。  
 函数体内部首先调用函数自身 `:`。  
 然后使用管道符 `|` 将前一个 `:` 的输出发送给下一个 `:`。  
 最后使用 `&` 将第二个 `:` 放入后台执行。  
最后的 `;:` 则是第一次调用定义的函数 `:`.  

```

这个结构导致函数会递归且以指数级的方式创建自身的新实例，每一个新实例又会创建两个新的子进程，迅速耗尽系统进程表(Process Table)。

为了防止这种攻击，我们可以通过设置每个用户可以创建的最大进程数(Number of Processes)来限制。在Linux中，这个限制由`nproc`资源项控制。最有效的防御手段是修改`/etc/security/limits.conf`文件，为普通用户设置一个较低的`nproc`硬限制(Hard Limit)。

以下是如何配置`/etc/security/limits.conf`来限制普通用户最大进程数的示例：
```bash
# <domain>      <type>  <item>         <value>
*               soft    nproc          1024
*               hard    nproc          2048
root            soft    nproc          unlimited
root            hard    nproc          unlimited
```
让我们来解析一下这些配置：  
① 第一行和第二行：  
`<domain>` 字段设置为 `*`，表示对所有非root用户生效。  
`<type>` 字段分别为 `soft` 和 `hard`，设置软限制和硬限制。  
`<item>` 字段设置为 `nproc`，表示限制的是用户最大进程数。  
`<value>` 字段分别为 `1024` 和 `2048`，表示软限制为1024个进程，硬限制为2048个进程。这意味着任何非root用户在其所有登录会话中创建的进程总数不能超过2048个。软限制1024是一个建议值，用户自己可以通过`ulimit`命令提升到硬限制2048以下，但不能超过硬限制。  
② 第三行和第四行：  
对 `root` 用户不设置进程数限制，因为root用户通常需要更高的权限和资源来管理系统。

**配置生效**

修改`/etc/security/limits.conf`后，这些限制通常在用户下一次登录时通过`pam_limits`模块生效。大多数现代Linux发行版的`/etc/pam.d/`目录下的服务配置文件（如`login`、`sshd`、`su`等）已经配置包含了`pam_limits.so`模块，例如：
```bash
# In /etc/pam.d/login or /etc/pam.d/sshd
...
session    required     pam_limits.so
...
```
当用户成功认证并启动新的会话时，`pam_limits.so`模块会被调用，它会读取`/etc/security/limits.conf`（及`/etc/security/limits.d/`目录下的文件），并根据用户的身份(UID/GID)应用相应的资源限制。

**验证配置**

用户重新登录后，可以使用`ulimit -u`命令来查看当前的进程数限制：
```bash
$ ulimit -u
1024
$ ulimit -Hu
2048
```
这表明软限制是1024，硬限制是2048，配置已成功生效。此时，如果一个用户尝试运行fork炸弹脚本，当其进程数达到2048时，系统将拒绝创建新的进程，从而阻止了攻击的蔓延，保护了系统的稳定性。

通过这个案例，我们看到`limits.conf`和`pam_limits`协同工作，为用户会话设置了持久化的资源限制，有效增强了系统的安全性。

### 6.2 优化数据库或Web服务器性能

高并发应用，例如繁忙的Web服务器（如Nginx, Apache）或数据库服务器（如MySQL, PostgreSQL），通常需要处理大量的并发连接。每一个连接或许多内部操作都需要消耗一个文件描述符(File Descriptor, FD)。如果系统或用户对文件描述符的数量设置了过低的限制，在高负载时，服务器可能会因为无法获取新的文件描述符而拒绝新的连接或操作，导致性能下降甚至服务中断。文件描述符的限制项是`nofile`（或`open files`）。

**问题表现**

在高并发场景下，服务器日志中可能会出现类似“Too many open files”的错误信息。
```bash
nginx: [alert] open socket #N failed (24: Too many open files)
mysql: [ERROR] Can't create thread to handle new connection (errno N)
```
这通常意味着当前进程（Web服务器或数据库进程）已经达到了其允许打开的文件描述符上限。

**解决方案**

解决方法是适当增加运行这些服务进程的用户的文件描述符限制。推荐使用`/etc/security/limits.conf`或`/etc/security/limits.d/`目录下的独立文件来设置，因为这能为特定的服务用户设置持久化的限制，而不会影响其他用户或整个系统。

假设你的Web服务器（如Nginx）运行在用户`www-data`下，数据库服务器（如MySQL）运行在用户`mysql`下。你可以创建一个新的limits文件，例如`/etc/security/limits.d/90-myservice.conf`：
```bash
# <domain>      <type>  <item>         <value>
@www-data       soft    nofile         65536
@www-data       hard    nofile         65536
mysql           soft    nofile         65536
mysql           hard    nofile         65536
```
解析：  
① `@www-data` 表示对`www-data`组内的所有用户生效。如果Nginx只运行在`www-data`用户下，也可以直接使用`www-data`作为`<domain>`。  
② `mysql` 表示对`mysql`用户生效。  
③ `soft nofile 65536` 和 `hard nofile 65536` 将这两个用户的软限制和硬限制都提高到了65536个文件描述符。这个值是一个常见的较高值，具体的最佳值取决于你的应用需求和系统硬件资源。设置软硬限制相同通常是为了避免软限制成为瓶颈，并简化管理。

**内核层面的上限**

需要注意的是，`/etc/security/limits.conf`设置的硬限制不能超过系统内核设定的文件描述符全局上限。这个全局上限由内核参数`/proc/sys/fs/file-max`控制。你可以通过`sysctl fs.file-max`或`cat /proc/sys/fs/file-max`来查看当前值。
```bash
$ cat /proc/sys/fs/file-max
999999
```
如果你的服务需要更高的文件描述符限制（例如超过10万），而`/proc/sys/fs/file-max`的值不够，你需要同时增加这个内核参数的值。修改`/etc/sysctl.conf`文件可以实现持久化设置：
```bash
# 在 /etc/sysctl.conf 中添加或修改
fs.file-max = 1000000
```
修改后，需要运行`sysctl -p`命令使其立即生效，或者重启系统。

**服务重启**

修改了`/etc/security/limits.conf`或`/etc/security/limits.d/`文件后，这些限制是通过`pam_limits`在用户**登录或会话启动**时应用的。对于系统服务来说，这意味着你需要**重启**相应的服务（如Nginx, MySQL）来使其在新的资源限制下启动。仅仅重新加载配置通常是不够的，因为进程已经启动，其资源限制是继承的。

**验证配置**

服务重启后，可以通过以下方法验证新的限制是否生效：  
① 找到服务进程的PID（进程ID），例如Nginx主进程。  
② 查看`/proc/[PID]/limits`文件：
```bash
$ ps aux | grep nginx  # 找到nginx主进程PID
nginx     12345  0.0  0.1  xxxxx  yyyyy ??  Ss   Aug01   0:10 nginx: master process /usr/sbin/nginx
$ cat /proc/12345/limits
Limit                     Soft Limit           Hard Limit           Units
...
Max open files            65536                65536                files
...
```
如果`Max open files`显示的是你设置的值（例如65536），则表示配置已成功应用于该进程。

这个案例展示了如何针对特定服务用户，通过修改`limits.conf`并配合内核参数，有效解除文件描述符的瓶颈，从而提升高并发服务的稳定性和性能。

### 6.3 为特定服务用户设置独立限制

在Linux系统中，许多应用和服务以独立的系统用户身份运行，以增强安全性（最小权限原则）。例如，数据库服务器、消息队列服务、缓存服务、Web服务器、应用服务器等。为这些特定的服务用户设置独立的、精细化的资源限制，可以进一步隔离不同服务之间的影响，防止一个服务的资源滥耗影响到其他服务或整个系统。

**场景示例**

考虑以下场景：  
⚝ 你有一个运行消息队列服务(Message Queue)的用户，它可能会创建大量队列相关的对象，可能也涉及大量连接（文件描述符），但通常不应该消耗过多的CPU时间或启动大量子进程。  
⚝ 你有一个运行缓存服务(Cache Service)的用户，它主要消耗内存，可能也需要一些文件描述符，但进程数和CPU时间通常不是其主要资源消耗。  
⚝ 你有一个运行Web应用的普通用户，它可能会执行用户提交的脚本，存在被滥用发起攻击的风险，需要限制其可以使用的进程数和CPU时间。

**配置方法**

使用`/etc/security/limits.conf`或`/etc/security/limits.d/`目录是为特定用户或组设置独立限制的标准方法。

例如，为消息队列用户`mquser`和缓存服务用户`cacheuser`设置限制，可以创建文件`/etc/security/limits.d/80-service-limits.conf`：
```bash
# 消息队列用户 mquser 的限制
# <domain>      <type>  <item>         <value>
mquser          soft    nofile         50000     # 允许打开大量文件/连接
mquser          hard    nofile         50000
mquser          soft    nproc          512       # 限制进程数，防止fork炸弹或过多工作进程
mquser          hard    nproc          1024
mquser          soft    cpu            unlimited # CPU时间不做限制
# 缓存服务用户 cacheuser 的限制
cacheuser       soft    nofile         10000     # 文件/连接需求较低
cacheuser       hard    nofile         10000
cacheuser       soft    nproc          128       # 进程数限制更严格
cacheuser       hard    nproc          256
cacheuser       soft    as             unlimited # 虚拟内存不做限制
cacheuser       hard    as             unlimited
cacheuser       soft    memlock        unlimited # 如果需要锁定内存，需要设置
cacheuser       hard    memlock        unlimited # 例如，如果缓存服务需要使用大页面或mmap锁定内存
```
解析：  
① 对`mquser`用户：  
 将`nofile`软硬限制都设为50000，以满足其可能的大量连接需求。  
 将`nproc`软限制设为512，硬限制设为1024，限制其创建的进程数，提高安全性。  
 对`cpu`（CPU时间）不设限制，允许其根据负载使用所需的CPU。  
② 对`cacheuser`用户：  
 `nofile`限制相对较低（10000）。  
 `nproc`限制比`mquser`更低（128/256），体现其应用特性。  
 `as`（进程地址空间/虚拟内存）和`memlock`（锁定内存大小）根据缓存服务的内存使用特性设置。如果缓存服务需要锁定部分内存在RAM中（例如为了高性能避免交换），则需要设置`memlock`限制，通常设为`unlimited`或一个非常大的值，但这需要root权限才能突破常规上限。

**注意事项**

⚝ **优先级：** 在`/etc/security/limits.conf`或`/etc/security/limits.d/`目录下，规则的优先级遵循“更具体的优先”以及“后出现的优先”的原则。例如，为单个用户设置的规则优先于为组设置的规则，为组设置的规则优先于为所有用户(`*`)设置的规则。在`/etc/security/limits.d/`中，文件名按字母顺序排序，后读取的文件中的规则可能覆盖先读取的文件中的规则。通常使用数字前缀来控制优先级。  
⚝ **PAM配置：** 确保服务的PAM配置（例如`/etc/pam.d/su`如果你是切换到服务用户，或者服务的启动脚本调用的PAM模块）包含`pam_limits.so`模块。  
⚝ **服务重启：** 修改`limits.conf`或`limits.d`文件后，必须**重启**相应的服务进程，新的限制才能生效。

通过为不同的服务用户设置独立的资源限制，系统管理员可以更精细地控制每个服务的资源消耗，提高系统的整体稳定性和弹性。这是一个重要的安全和性能调优实践。

### 6.4 控制批量作业(Batch Jobs)的资源消耗

在高性能计算(High-Performance Computing, HPC)环境、科学计算平台或企业内部的数据处理系统中，用户经常提交批量作业(Batch Jobs)到作业调度系统（如Slurm, PBS Professional, LSF, GridEngine）。这些作业可能由普通用户提交，长时间运行，并且可能消耗大量的CPU时间、内存或临时文件空间。如果不加以控制，单个资源消耗过度的作业可能会影响整个集群的稳定性和其他用户的作业。

传统的Linux资源限制(`ulimit`, `limits.conf`, `pam_limits`)可以与作业调度系统结合使用，或者作为作业调度系统本身施加更严格限制的基础。

**应用场景**

⚝ **限制单个作业的CPU时间：** 防止意外的无限循环或运行时间过长的作业占用计算资源。  
⚝ **限制单个作业的内存使用：** 防止作业因内存泄漏或过度分配导致系统内存不足(Out-Of-Memory, OOM)而崩溃或影响其他作业。  
⚝ **限制临时文件空间：** 防止作业在`/tmp`或其他临时目录创建过多或过大的文件，耗尽磁盘空间。

**实现方式**

① **通过`limits.conf`为提交作业的用户设置全局限制：** 这是最基础的方式。在用户登录到提交节点时，`pam_limits`会应用`/etc/security/limits.conf`中为其设置的限制。这些限制会被作业进程继承，成为作业可以使用的资源上限。例如，限制所有普通用户的CPU时间：
```bash
# 在 /etc/security/limits.conf 或 limits.d/ 文件中
# <domain>      <type>  <item>         <value>
@users          soft    cpu            1800      # 软限制 CPU 时间 30 分钟
@users          hard    cpu            3600      # 硬限制 CPU 时间 60 分钟

```
这里的`@users`假定你的所有普通用户都在`users`组中。`cpu`的单位通常是秒。当进程达到软限制时，系统会发出一个信号（通常是`SIGXCPU`），如果程序没有处理这个信号，它可能会继续运行直到达到硬限制，此时系统会强制终止进程（发送`SIGKILL`）。

② **在作业脚本中使用`ulimit`命令：** 用户可以在提交的作业脚本的开头显式地使用`ulimit`命令来设置或降低当前作业进程及其子进程的资源限制。
```bash
#!/bin/bash
#SBATCH --job-name=my_long_job
#SBATCH --time=01:00:00 # 作业调度系统的时间限制
# 在作业脚本内部设置资源限制
ulimit -t 3000  # 将当前进程及其子进程的CPU时间限制设置为 3000 秒 (50 分钟)
ulimit -v 8000000 # 将虚拟内存限制设置为 8GB (单位通常是 KB)
# 运行你的计算程序
./my_computation_program

```
这种方式允许用户为特定的作业设置比其用户全局限制更严格的限制。但是，`ulimit`设置不能超过父进程（这里是作业调度系统的执行代理进程）已经拥有的硬限制。如果`/etc/security/limits.conf`为用户设置的硬限制低于`ulimit`中尝试设置的值，则`ulimit`会失败。

③ **作业调度系统自身的资源管理功能：** 大多数现代作业调度系统提供了更强大和灵活的资源管理功能，通常基于Linux的控制组(cgroups)。作业调度系统可以在启动作业进程时，将作业进程放入一个特定的cgroup中，并使用cgroupv1或cgroupv2的机制来限制CPU、内存、I/O等资源的使用。cgroups提供的资源控制通常比传统的`ulimit`更为精细和强制。在这种情况下，`limits.conf`和`pam_limits`设置的限制会作为用户在进入作业调度系统环境之前的**基础限制**，而cgroups则提供了作业运行时的**二次限制或更强的隔离**。

**与cgroups的关系**

虽然本章主要聚焦于`ulimit`、`limits.conf`和`pam_limits`这些传统的资源限制机制，但值得注意的是，cgroups是Linux中更现代、功能更丰富的资源管理工具。它们通常用于容器化技术（如Docker, Kubernetes）和作业调度系统。传统的资源限制主要应用于用户登录会话和由其直接启动的进程，而cgroups可以对任意进程组进行资源控制，并且控制粒度更细（例如，可以限制CPU份额而非总量，限制磁盘I/O带宽等）。在许多复杂的环境中，传统的资源限制与cgroups是并存的，前者提供会话级别的默认限制，后者提供更细粒度的作业或服务隔离和控制。本书附录或更高级的主题中可能会进一步探讨cgroups。

通过合理利用`limits.conf`和`ulimit`，结合（或作为基础）作业调度系统的资源管理能力，系统管理员可以有效地管理批量作业对系统资源的消耗，保障计算环境的稳定性和公平性。