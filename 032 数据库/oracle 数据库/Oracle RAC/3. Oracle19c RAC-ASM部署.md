# 3. Oracle19c RAC-ASM部署

## 安装规划

### 软件规划

|**软件**|**版本**|
| ------------------| ---------------------------------------------|
|虚拟机软件|VMware-workstation-full-16.1.1-17801498.exe|
|操作系统软件|CentOS-7-x86\_64-DVD-1810.iso|
|Oracle数据库软件|LINUX.X64\_193000\_db\_home.zip|
|GI软件|LINUX.X64\_193000\_grid\_home.zip|
|openfiler软件|openfileresa-2.99.1-x86\_64-disc1.iso|
|rlwrap|rlwrap-0.37-1.el6.x86\_64.rpm|

[https://www.oracle.com/database/technologies/oracle19c-linux-downloads.html]()

### 虚拟机规划

#### 主机信息

|主机名|**操作系统**|**cpu核数**|**内存**|**硬盘**|**网卡**|
| ----------| -----------------| -----| ----| ------| --------------------------------|
|rac-01|Centos7.6|4核|8G|100G|2个网卡，1块public，1块private|
|rac-02|Centos7.6|4核|8G|100G|2个网卡，1块public，1块private|
|rac-data|openfiler自带的|4核|8G|450G|与ora19c-rac1的public同一网段|

#### 网络规划

|**节点名称**|**public-ip**|**private-ip**|**vip**|**scan-ip**|
| ----------| -----------------| --------------| -----------------| -----------------|
|rac-01|192.168.245.141|10.10.10.141|192.168.245.101|192.168.245.140|
|rac-02|192.168.245.142|10.10.10.142|192.168.245.102||
|rac-data|192.168.245.150||||

#### 硬盘规划

|**目录**|**大小**|
| -------| -----|
|/tmp|10G|
|swap|8G|
|/boot|1G|
|/|10G|
|/u01|70G|

#### ASM磁盘组

在这次安装中，磁盘规划如下：

|**磁盘组名称**|**磁盘数量**|**单个磁盘大小**|**功能说明**|
| ------| ---| ------| -----------------------------------|
|OCR|3|10GB|存放OCR及GI management repository|
|DATA|2|20GB|存放数据库的数据|
|ARCH|1|20GB|存放归档数据|

### Oracle规划

#### 用户组和用户

|**用户组**|**说明**|
| -----------| -------------------------|
|oinstall|Oracle清单和软件所有者|
|dba|数据库管理员、RAC管理员|
|oper|DBA操作员组|
|backupdba|备份管理员|
|dgdba|DG管理员|
|kmdba|KM管理员|
|asmdba|ASM数据库管理员组|
|asmoper|ASM操作员组|
|asmadmin|Oracle自动存储管理组|

|**用户**|**用户所属主组**|**用户所属其他组**|**用户家目录**|
| --------| ----------| ---------------------------------------| --------------|
|oracle|oinstall|dba,asmdba,backupdba,dgdba,kmdba,oper|/home/oracle|
|grid|oinstall|dba,asmadmin,asmdba,asmoper|/home/grid|

#### 软件目录规划

|目录|路径|说明|
| ---------------------------| --------------------------------------| --------------------|
|ORACLE\_BASE（oracle）|/u01/app/oracle|oracle基目录|
|ORACLE\_HOME（oracle）|/u01/app/oracle/product/19c/db\_1|oracle用户HOME目录|
|GRID\_BASE（grid）|/u01/app/grid|grid基目录|
|GRID\_HOME（grid）|/u01/app/19c/grid|grid用户HOME目录|

#### 整体数据库安装规划

|规划内容|规划描述|
| ----------| ----------------------------|
|内存规划|SGA(4GB) PGA(500MB)|
|字符集|AL32UTF8|
|归档模式|非（安装好后手动开启归档）|
|redo|5组 每组200M|
|undo|2G 自动扩展 最大4G|
|temp|4G|
|闪回配置|4G大小|

## 安装前准备（rac1和rac2）

### 虚拟机准备

* 创建虚拟机 KVM 部署及使用
* 配置双网卡 KVM 虚拟机网络设置
* 创建数据盘 配置共享存储 本文后面会有详细步骤

‍

### 基础环境设置

```bash
# 调整字符集
localectl set-locale LANG=en_US.UTF8 && localectl status|grep LANG
# 主机时间、时区检查
timedatectl
# 设置时区
timedatectl set-timezone "Asia/Shanghai"
#timedatectl set-time "2012-10-30 18:17:16"

# 将系统时间同步给硬件时间
#date -s "2023-04-03 11:10:00" &&  hwclock --systohc

# 检查防火墙状态
systemctl status firewalld.service 
# 关闭防火墙
systemctl stop firewalld.service 
# 关闭防火墙开机自启
systemctl disable firewalld.service

# 关闭Selinux
sed -i 's#SELINUX=.*#SELINUX=disabled#' /etc/selinux/config 
setenforce 0
```

### 配置host文件

```bash
cat << EOF >> /etc/hosts
#pub-ip
192.168.31.201 rac-01
192.168.31.202 rac-02
192.168.31.203 rac-data

#pri-ip
10.10.0.201 rac-01-priv
10.10.0.202 rac-02-priv
10.10.0.203 rac-data

#vip
192.168.31.21 rac-01-vip
192.168.31.22 rac-02-vip

#scan-ip
192.168.31.99 rac-scan
EOF
```

### 安装依赖包

rlwrap.rpm download: [https://pkgs.org/download/rlwrap](https://pkgs.org/download/rlwrap)

```bash
yum install -y bc unzip compat-libcap1* compat-libcap* binutils compat-libstdc++-33 elfutils-libelf elfutils-libelf-devel gcc gcc-c++ glibc-2.5 glibc-common glibc-devel glibc-headers ksh libaio libaio-devel libgcc libstdc++ libstdc++-devel make sysstat unixODBC unixODBC-devel binutils* compat-libstdc* elfutils-libelf* gcc* glibc* ksh* libaio* libgcc* libstdc* make* sysstat* libXp* glibc-kernheaders net-tools-* iscsi-initiator-utils udev xclock* kmod kmod-libs nfs-utils libXi libXtst smartmontools

#额外的安装包
# cvuqdisk-1.0.10-1.rpm          # 软件包 cvuqdisk-1.0.10-1 可以从网格基础架构安装目录的 cv/rpm 目录下安装。
su - root
cd /data/app/19.3.0/grid/cv/rpm
export CVUQDISK_GRP=asmadmin
rpm –ivh cvuqdisk-1.0.10-1.rpm
# 将cvuqdisk-1.0.10-1.rpm拷贝到另一节点，执行安装。

# rlwrap-0.37-1.el6.x86_64.rpm   # 解决sqlplus命令行工具时，不好回退，或者刚输入的命令想再次执行，无法通过上下翻页切换的情况。
# kmod-20-21.el7.x86_64.rpm      # yum install kmod kmod-libs
# kmod-libs-20-21.el7.x86_64.rpm # 

wget https://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/r/rlwrap-0.45.2-2.el7.x86_64.rpm
yum -y install  rlwrap-0.45.2-2.el7.x86_64.rpm
```

### 修改内核参数

```bash
echo '
kernel.shmmax = 277495689510912
kernel.shmmni = 4096
kernel.sem = 250 32000 100 128
net.core.rmem_default = 262144
net.core.rmem_max = 4194304
net.core.wmem_default = 262144
net.core.wmem_max = 1048586
fs.file-max = 6815744
kernel.shmall = 67747971072
net.ipv4.tcp_max_tw_buckets = 6000
net.ipv4.ip_local_port_range = 9000 65500
net.ipv4.tcp_tw_recycle = 0
net.ipv4.tcp_tw_reuse = 1
#net.core.somaxconn = 262144
net.core.netdev_max_backlog = 262144
net.ipv4.tcp_max_orphans = 262144
net.ipv4.tcp_max_syn_backlog = 262144
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_syn_retries = 1
net.ipv4.tcp_fin_timeout = 1
net.ipv4.tcp_keepalive_time = 30
net.ipv4.tcp_keepalive_probes = 6
net.ipv4.tcp_keepalive_intvl = 5
net.ipv4.tcp_timestamps = 0
fs.aio-max-nr = 1048576
net.ipv4.conf.all.rp_filter = 2
net.ipv4.conf.default.rp_filter = 2' >> /etc/sysctl.conf

# 生成系统参数
sysctl -p 

```

### 配置资源限制参数

```bash
echo '
oracle   soft   nofile    1024
oracle   hard   nofile    65536
oracle   soft   nproc    16384
oracle   hard   nproc    16384
oracle   soft   stack    10240
oracle   hard   stack    32768
oracle   hard   memlock    134217728
oracle   soft   memlock    134217728

grid   soft   nofile    1024
grid   hard   nofile    65536
grid   soft   nproc    16384
grid   hard   nproc    16384
grid   soft   stack    10240
grid   hard   stack    32768
grid   hard   memlock    134217728
grid   soft   memlock    134217728' >> /etc/security/limits.conf
```

```bash
echo '
if [ $USER = "oracle" ] || [ $USER = "grid" ]; then
   if [ $SHELL = "/bin/ksh" ]; then
      ulimit -p 16384
      ulimit -n 65536
      else
      ulimit -u 16384 -n 65536
   fi
fi
' >> /etc/profile

# 使环境变量立即生效
source /etc/profile

```

### 修改登录验证

```bash
echo 'session    required     pam_limits.so' >> /etc/pam.d/login
```

### 创建用户组和用户

```bash
groupadd -g 601 oinstall
groupadd -g 602 dba
groupadd -g 603 oper
groupadd -g 604 backupdba
groupadd -g 605 dgdba
groupadd -g 606 kmdba
groupadd -g 607 asmdba
groupadd -g 608 asmoper
groupadd -g 609 asmadmin
useradd -u 601 -g oinstall -G asmadmin,asmdba,dba,asmoper grid
useradd -u 602 -g oinstall -G dba,backupdba,dgdba,kmdba,asmadmin,oper,asmdba oracle
# 修改grid和oracle的密码
echo 'Ninestar123' | passwd --stdin grid
echo 'Ninestar123' | passwd --stdin oracle

```

### 创建目录

```bash
# 以root用户，创建Oracle Inventory 目录
mkdir -p /data/u01/app/oraInventory
chown -R grid:oinstall /data/u01/app/oraInventory
chmod -R 775 /data/u01/app/oraInventory

# 以root用户，创建GI HOME目录
mkdir -p /data/u01/app/grid
mkdir -p /data/u01/app/19c/grid
chown -R grid:oinstall /data/u01/app/grid
chmod -R 775 /data/u01/app/grid
chown -R grid:oinstall /data/u01/app/19c
chmod -R 775 /data/u01/app/19c/

# 以root用户，创建Oracle Base目录
mkdir -p /data/u01/app/oracle
mkdir /data/u01/app/oracle/cfgtoollogs 
chown -R oracle:oinstall /data/u01/app/oracle
chmod -R 775 /data/u01/app/oracle

# 以root用户，创建Oracle RDBMS Home目录
mkdir -p /data/u01/app/oracle/product/19c/db_1
chown -R oracle:oinstall /data/u01/app/oracle/product/19c/db_1
chmod -R 775 /data/u01/app/oracle/product/19c/db_1
```

### 添加用户环境变量

* grid ora19c-rac1

  ```bash
  su - grid
  cat <<EOF >> ~/.bash_profile
  #PS1="[`whoami`@`hostname`:"'$PWD]$'
  #export PS1
  umask 022
  export TMP=/tmp
  export TMPDIR=$TMP
  export ORACLE_SID=+ASM1
  export ORACLE_TERM=xterm;
  export GRID_BASE=/data/u01/app/grid
  export GRID_HOME=/data/u01/app/19c/grid
  export NLS_LANG="AMERICAN_AMERICA.AL32UTF8"
  export NLS_DATE_FORMAT="yyyy-mm-dd HH24:MI:SS"
  export TNS_ADMIN=$ORACLE_HOME/network/admin
  export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib  
  export PATH=.:$PATH:$HOME/bin:$ORACLE_HOME/bin
  export THREADS_FLAG=native
  export LANG="ZH_CN.UTF-8"
  alias sqlplus='rlwrap sqlplus'
  alias asmcmd='rlwrap asmcmd'
  alias rman='rlwrap rman'
  EOF
  source ~/.bash_profile

  ```

* grid ora19c-rac2

  ```
  su - grid
  cat <<EOF >> ~/.bash_profile
  #PS1="[`whoami`@`hostname`:"'$PWD]$'
  #export PS1
  umask 022
  export TMP=/tmp
  export TMPDIR=$TMP
  export ORACLE_SID=+ASM2
  export ORACLE_TERM=xterm;
  export GRID_BASE=/data/u01/app/grid
  export GRID_HOME=/data/u01/app/19c/grid
  export NLS_LANG="AMERICAN_AMERICA.AL32UTF8"
  export NLS_DATE_FORMAT="yyyy-mm-dd HH24:MI:SS"
  export TNS_ADMIN=$ORACLE_HOME/network/admin
  export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib  
  export PATH=.:$PATH:$HOME/bin:$ORACLE_HOME/bin
  export THREADS_FLAG=native
  export LANG="ZH_CN.UTF-8"
  alias sqlplus='rlwrap sqlplus'
  alias asmcmd='rlwrap asmcmd'
  alias rman='rlwrap rman'
  EOF
  source ~/.bash_profile

  ```

* oracle ora19c-rac1

  ```
  su - oracle
  cat <<EOF >> ~/.bash_profile
  #PS1="[`whoami`@`hostname`:"'$PWD]$'
  #export PS1
  export TMP=/tmp
  export TMPDIR=$TMP
  export ORACLE_HOSTNAME=rac-01
  export ORACLE_BASE=/data/u01/app/oracle
  export ORACLE_HOME=/data/u01/app/oracle/product/19c/db_1
  export ORACLE_SID=orcl1
  export NLS_LANG="AMERICAN_AMERICA.AL32UTF8"
  export NLS_DATE_FORMAT="yyyy-mm-dd HH24:MI:SS"
  export TNS_ADMIN=$ORACLE_HOME/network/admin
  export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib  
  export PATH=.:$PATH:$HOME/bin:$ORACLE_BASE/product/19c/db_1/bin:$ORACLE_HOME/bin
  export THREADS_FLAG=native
  export LANG="ZH_CN.UTF-8"
  alias sqlplus='rlwrap sqlplus'
  alias rman='rlwrap rman'
  EOF
  source ~/.bash_profile

  ```

* oracle ora19c-rac2

  ```

  su - oracle
  cat << EOF >> ~/.bash_profile
  #PS1="[`whoami`@`hostname`:"'$PWD]$'
  #export PS1
  export TMP=/tmp
  export TMPDIR=$TMP
  export ORACLE_HOSTNAME=rac-02
  export ORACLE_BASE=/data/u01/app/oracle
  export ORACLE_HOME=/data/u01/app/oracle/product/19c/db_1
  export ORACLE_SID=orcl2
  export NLS_LANG="AMERICAN_AMERICA.AL32UTF8"
  export NLS_DATE_FORMAT="yyyy-mm-dd HH24:MI:SS"
  export TNS_ADMIN=$ORACLE_HOME/network/admin
  export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib  
  export PATH=.:$PATH:$HOME/bin:$ORACLE_BASE/product/19c/db_1/bin:$ORACLE_HOME/bin
  export THREADS_FLAG=native
  export LANG="ZH_CN.UTF-8"
  alias sqlplus='rlwrap sqlplus'
  alias rman='rlwrap rman'
  EOF
  source ~/.bash_profile
  ```

‍

### 节点免密互信

参考：密钥登录

```bash
### rac-01
su - oracle
ssh-keygen
ssh-copy-id rac-02


su - grid
ssh-keygen
ssh-copy-id rac-02

### rac-02

su - oracle
ssh-keygen
ssh-copy-id rac-01


su - grid
ssh-keygen
ssh-copy-id rac-01

```

### 关闭透明大页

```bash
# 查看是否启用了  Transparent Hugepages
cat /sys/kernel/mm/transparent_hugepage/enabled
[always] madvise never  # 启用状态

# 关闭
echo never > /sys/kernel/mm/transparent_hugepage/enabled 
echo never > /sys/kernel/mm/transparent_hugepage/defrag

# 永久禁用THP(Transparent HugePages )--直接执行立即生效
cat <<EOF >> /etc/rc.d/rc.local
#-----------------------------------------------------
echo never > /sys/kernel/mm/transparent_hugepage/enabled 
echo never > /sys/kernel/mm/transparent_hugepage/defrag
EOF
```

‍

### 关闭 ZEROCONF

```bash
echo "NOZEROCONF=yes" >> /etc/sysconfig/network
```

### 移除操作系统时间同步配置

```bash
mv /etc/chrony.conf /etc/chrony.conf.bak
```

### 添加shm

```bash
#修改/etc/fstab,添加以下配置，设置成实际内存的一半。
vi /etc/fstab
tmpfs /dev/shm tmpfs defaults,size=4g 0 0

# 添加完上面的命令之后执行
mount -o remount /dev/shm
```

‍

### 配置共享存储

#### 方式一：配置ISCSI挂载外部存储

kvm：在虚拟机上（存储服务器）准备磁盘

```bash
# 创建裸设备
qemu-img create -f raw rac-storage-ocr_1.raw 10G
qemu-img create -f raw rac-storage-ocr_2.raw 10G
qemu-img create -f raw rac-storage-ocr_3.raw 10G
...
root@localhost:/data/virthost # ll
total 14291104
-rw------- 1 root root 53695545344 Feb 20 14:08 CentOS7.9_templ.qcow2
-rw------- 1 qemu qemu  5024317440 Feb 20 14:49 rac-01.qcow2
-rw------- 1 qemu qemu  5028511744 Feb 20 14:49 rac-02.qcow2
-rw------- 1 qemu qemu  2276917248 Feb 20 14:40 rac-date.qcow2
-rw-r--r-- 1 root root 21474836480 Feb 20 14:50 rac-storage-arch_1.raw
-rw-r--r-- 1 root root 21474836480 Feb 20 14:50 rac-storage-data_1.raw
-rw-r--r-- 1 root root 21474836480 Feb 20 14:50 rac-storage-data_2.raw
-rw-r--r-- 1 root root 10737418240 Feb 20 14:49 rac-storage-ocr_1.raw
-rw-r--r-- 1 root root 10737418240 Feb 20 14:49 rac-storage-ocr_2.raw
-rw-r--r-- 1 root root 10737418240 Feb 20 14:49 rac-storage-ocr_3.raw


# 热挂载裸设备到虚拟机
virsh attach-disk rac-data --source /data/virthost/rac-storage-ocr_1.raw --config --target vdb --persistent --subdriver raw
virsh attach-disk rac-data --source /data/virthost/rac-storage-ocr_2.raw --config --target vdc --persistent --subdriver raw
virsh attach-disk rac-data --source /data/virthost/rac-storage-ocr_3.raw --config --target vde --persistent --subdriver raw
...


[root@rac-data ~]# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0     11:0    1 1024M  0 rom  
vda    253:0    0   50G  0 disk 
├─vda1 253:1    0    1G  0 part /boot
├─vda2 253:2    0    5G  0 part [SWAP]
└─vda3 253:3    0   44G  0 part /
vdb    253:16   0   10G  0 disk 
vdc    253:32   0   10G  0 disk 
vdd    253:48   0   10G  0 disk 
vde    253:64   0   20G  0 disk 
vdf    253:80   0   20G  0 disk 
vdg    253:96   0   20G  0 disk 
```

参考 iSCSI 在存储服务器上配置 target 最后配置信息如下：

```bash
/iscsi/iqn.20.../tpg1/portals> cd /
/> ls
o- / .................................................................. [...]
  o- backstores ....................................................... [...]
  | o- block ........................................... [Storage Objects: 6]
  | | o- block-arch-1 ............. [/dev/vdg (20.0GiB) write-thru activated]
  | | | o- alua ............................................ [ALUA Groups: 1]
  | | |   o- default_tg_pt_gp ................ [ALUA state: Active/optimized]
  | | o- block-data-1 ............. [/dev/vde (20.0GiB) write-thru activated]
  | | | o- alua ............................................ [ALUA Groups: 1]
  | | |   o- default_tg_pt_gp ................ [ALUA state: Active/optimized]
  | | o- block-data-2 ............. [/dev/vdf (20.0GiB) write-thru activated]
  | | | o- alua ............................................ [ALUA Groups: 1]
  | | |   o- default_tg_pt_gp ................ [ALUA state: Active/optimized]
  | | o- block-ocr-1 .............. [/dev/vdb (10.0GiB) write-thru activated]
  | | | o- alua ............................................ [ALUA Groups: 1]
  | | |   o- default_tg_pt_gp ................ [ALUA state: Active/optimized]
  | | o- block-ocr-2 .............. [/dev/vdc (10.0GiB) write-thru activated]
  | | | o- alua ............................................ [ALUA Groups: 1]
  | | |   o- default_tg_pt_gp ................ [ALUA state: Active/optimized]
  | | o- block-ocr-3 .............. [/dev/vdd (10.0GiB) write-thru activated]
  | |   o- alua ............................................ [ALUA Groups: 1]
  | |     o- default_tg_pt_gp ................ [ALUA state: Active/optimized]
  | o- fileio .......................................... [Storage Objects: 0]
  | o- pscsi ........................................... [Storage Objects: 0]
  | o- ramdisk ......................................... [Storage Objects: 0]
  o- iscsi ..................................................... [Targets: 1]
  | o- iqn.2024-02.storage.oracle:server .......................... [TPGs: 1]
  |   o- tpg1 ........................................ [no-gen-acls, no-auth]
  |     o- acls ................................................... [ACLs: 1]
  |     | o- iqn.2024-02.storage.oracle:client ............. [Mapped LUNs: 6]
  |     |   o- mapped_lun0 .................... [lun0 block/block-ocr-1 (rw)]
  |     |   o- mapped_lun1 .................... [lun1 block/block-ocr-2 (rw)]
  |     |   o- mapped_lun2 .................... [lun2 block/block-ocr-3 (rw)]
  |     |   o- mapped_lun3 ................... [lun3 block/block-data-1 (rw)]
  |     |   o- mapped_lun4 ................... [lun4 block/block-data-2 (rw)]
  |     |   o- mapped_lun5 ................... [lun5 block/block-arch-1 (rw)]
  |     o- luns ................................................... [LUNs: 6]
  |     | o- lun0 ......... [block/block-ocr-1 (/dev/vdb) (default_tg_pt_gp)]
  |     | o- lun1 ......... [block/block-ocr-2 (/dev/vdc) (default_tg_pt_gp)]
  |     | o- lun2 ......... [block/block-ocr-3 (/dev/vdd) (default_tg_pt_gp)]
  |     | o- lun3 ........ [block/block-data-1 (/dev/vde) (default_tg_pt_gp)]
  |     | o- lun4 ........ [block/block-data-2 (/dev/vdf) (default_tg_pt_gp)]
  |     | o- lun5 ........ [block/block-arch-1 (/dev/vdg) (default_tg_pt_gp)]
  |     o- portals ............................................. [Portals: 1]
  |       o- 0.0.0.0:3260 .............................................. [OK]
  o- loopback .................................................. [Targets: 0]
/> 

```

参考 iSCSI 在rac01和rac02上配置 initiator 客户端

‍

##### **绑定 UDEV 共享磁盘**

*RAC*+ASM下要求多节点的LUN DISK名字一致，如果不*使用udev*、asmlib这些设备名绑定服务的话，无法确保设备名一致。

使用udev配置磁盘有2种方法，第一种是直接fdisk格式化磁盘，拿到/dev/sd*1的磁盘，然后使用udev绑定raw，第二种是获取wwid来绑定设备，生产中太长使用第二种方法。

###### 方法1：直接使用raw

格式化磁盘，在1个节点上执行

```bash
# 在节点1上格式化，以/dev/sdb为例：

[root@node1 ~]# fdisk /dev/sdb

The number of cylinders for this disk is set to 3824.
There is nothing wrong with that, but this is larger than 1024,
and could in certain setups cause problems with:
1) software that runs at boot time (e.g., old versions of LILO)
2) booting and partitioning software from other OSs
   (e.g., DOS FDISK, OS/2 FDISK)

Command (m for help): n
Command action
   e   extended
   p   primary partition (1-4)
p
Partition number (1-4): 1
First cylinder (1-3824, default 1): 
Using default value 1
Last cylinder or +size or +sizeM or +sizeK (1-3824, default 3824): 
Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.
Syncing disks.

```

在2个节点上配置raw设备

```bash
[root@node1 ~]# vi /etc/udev/rules.d/60-raw.rules
 # 在后面添加

ACTION=="add", KERNEL=="sdb1", RUN+="/bin/raw /dev/raw/raw1 %N"
ACTION=="add", KERNEL=="sdc1", RUN+="/bin/raw /dev/raw/raw2 %N"
ACTION=="add", KERNEL=="sdd1", RUN+="/bin/raw /dev/raw/raw3 %N"
ACTION=="add", KERNEL=="sde1", RUN+="/bin/raw /dev/raw/raw4 %N"
ACTION=="add", KERNEL=="sdf1", RUN+="/bin/raw /dev/raw/raw5 %N"
ACTION=="add", KERNEL=="sdg1", RUN+="/bin/raw /dev/raw/raw6 %N"


KERNEL=="raw[1]", MODE="0660", OWNER="grid", GROUP="asmadmin"
KERNEL=="raw[2]", MODE="0660", OWNER="grid", GROUP="asmadmin"
KERNEL=="raw[3]", MODE="0660", OWNER="grid", GROUP="asmadmin"
KERNEL=="raw[4]", MODE="0660", OWNER="grid", GROUP="asmadmin"
KERNEL=="raw[5]", MODE="0660", OWNER="grid", GROUP="asmadmin"
KERNEL=="raw[6]", MODE="0660", OWNER="grid", GROUP="asmadmin"
```

启动裸设备，2个节点都要执行

```bash
start_udev
```

查看裸设备，2个节点都要查看，如果有节点不能看到下面的raw设备信息，重启节点

```bash
[root@node1 ~]# raw -qa
/dev/raw/raw1:    bound to major 8, minor 17
/dev/raw/raw2:    bound to major 8, minor 33
/dev/raw/raw3:    bound to major 8, minor 49
/dev/raw/raw4:    bound to major 8, minor 65
/dev/raw/raw5:    bound to major 8, minor 81
/dev/raw/raw6:    bound to major 8, minor 97
```

‍

###### 方法2：使用wwid来绑定设备

知识点参考 udev

编辑/etc/scsi_id.config文件，2个节点都要编辑

```bash
[root@node1 ~]# echo "options=--whitelisted --replace-whitespace"  >> /etc/scsi_id.config
```

将磁盘wwid信息写入99-oracle-asmdevices.rules文件，2个节点都要编辑

```bash
# 根据lsblk修改盘符
[root@rac-02 ~]# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   10G  0 disk 
sdb      8:16   0   10G  0 disk 
sdc      8:32   0   10G  0 disk 
sdd      8:48   0   20G  0 disk 
sde      8:64   0   20G  0 disk 
sdf      8:80   0   20G  0 disk 
sr0     11:0    1 1024M  0 rom  
vda    253:0    0   50G  0 disk 
├─vda1 253:1    0    1G  0 part /boot
├─vda2 253:2    0    5G  0 part [SWAP]
└─vda3 253:3    0   44G  0 part /
[root@rac-02 ~]# 

### 以下脚本适用于Centos7
for i in a b c d e f ;
do 
echo "KERNEL==\"sd*\",SUBSYSTEM==\"block\",PROGRAM==\"/lib/udev/scsi_id -g -u -d /dev/\$name\",RESULT==\"`/lib/udev/scsi_id -g -u -d /dev/sd$i`\",SYMLINK+=\"asm-sd$i\",OWNER=\"grid\",GROUP=\"asmadmin\",MODE=\"0660\"" >> /etc/udev/rules.d/99-oracle-asmdevices.rules
done
```

查看99-oracle-asmdevices.rules文件，2个节点都要查看

```bash
[root@ora19c-rac1 grid]# cat /etc/udev/rules.d/99-oracle-asmdevices.rules 
---------------------------------------------
KERNEL=="sd*",SUBSYSTEM=="block",PROGRAM=="/lib/udev/scsi_id -g -u -d /dev/$name",RESULT=="36001405449ab3f0199d4ebeb62d8cea6",SYMLINK+="asm-sda",OWNER="grid",GROUP="asmadmin",MODE="0660"
KERNEL=="sd*",SUBSYSTEM=="block",PROGRAM=="/lib/udev/scsi_id -g -u -d /dev/$name",RESULT=="36001405bc7186d81669471b81b80ce8c",SYMLINK+="asm-sdb",OWNER="grid",GROUP="asmadmin",MODE="0660"
KERNEL=="sd*",SUBSYSTEM=="block",PROGRAM=="/lib/udev/scsi_id -g -u -d /dev/$name",RESULT=="36001405c912cb43fe3e435a85518c98e",SYMLINK+="asm-sdc",OWNER="grid",GROUP="asmadmin",MODE="0660"
KERNEL=="sd*",SUBSYSTEM=="block",PROGRAM=="/lib/udev/scsi_id -g -u -d /dev/$name",RESULT=="3600140527afccdfe1d54094a80a8a34b",SYMLINK+="asm-sdd",OWNER="grid",GROUP="asmadmin",MODE="0660"
KERNEL=="sd*",SUBSYSTEM=="block",PROGRAM=="/lib/udev/scsi_id -g -u -d /dev/$name",RESULT=="36001405405c32a717134c92a67b555d9",SYMLINK+="asm-sde",OWNER="grid",GROUP="asmadmin",MODE="0660"
KERNEL=="sd*",SUBSYSTEM=="block",PROGRAM=="/lib/udev/scsi_id -g -u -d /dev/$name",RESULT=="3600140516a8c99d91004e60883b4626b",SYMLINK+="asm-sdf",OWNER="grid",GROUP="asmadmin",MODE="0660"
```

启动设备，2个节点都要执行

```bash
udevadm control --reload  
udevadm trigger
```

确认磁盘已经添加成功

```bash
[root@rac-01 ~]# ll /dev | grep asm-
lrwxrwxrwx 1 root root            3 2月  20 16:04 asm-sda -> sda   # ocr1
lrwxrwxrwx 1 root root            3 2月  20 16:04 asm-sdb -> sdb   # ocr2
lrwxrwxrwx 1 root root            3 2月  20 16:04 asm-sdc -> sdc   # ocr3
lrwxrwxrwx 1 root root            3 2月  20 16:04 asm-sdd -> sdd   # data1
lrwxrwxrwx 1 root root            3 2月  20 16:04 asm-sde -> sde   # data2
lrwxrwxrwx 1 root root            3 2月  20 16:04 asm-sdf -> sdf   # arch1
```

‍

### 最后可以做一下快照

KVM 虚拟机克隆和快照

```bash
virsh snapshot-create rac-01
virsh snapshot-create rac-02
#virsh snapshot-create rac-data
```

---

## 安装（rac1）

### 安装 grid

```bash
su - grid
cd ～/
# 上传 LINUX.X64_193000_grid_home.zip 到 ～/

# 解压
unzip -d $GRID_HOME LINUX.X64_193000_grid_home.zip
# 安装cvuqdisk-1.0.10-1.rpm
rpm -ivh $GRID_HOME/cv/rpm/cvuqdisk-1.0.10-1.rpm 

# 安装前检查
$GRID_HOME/runcluvfy.sh stage -pre crsinst -n rac-01,rac-02 -fixup -verbose
  ------------  ------------------------  ------------------------
  rac-02        no                        passed        
  rac-01        no                        passed        
Verifying Daemon "proxyt" not configured and running ...PASSED
Verifying User Equivalence ...PASSED
Verifying RPM Package Manager database ...INFORMATION (PRVG-11250)
Verifying /dev/shm mounted as temporary file system ...PASSED
Verifying File system mount options for path /var ...PASSED
Verifying DefaultTasksMax parameter ...PASSED
Verifying zeroconf check ...PASSED
Verifying ASM Filter Driver configuration ...PASSED

Pre-check for cluster services setup was successful. 
Verifying RPM Package Manager database ...INFORMATION
PRVG-11250 : The check "RPM Package Manager database" was not performed because
it needs 'root' user privileges.


CVU operation performed:      stage -pre crsinst
Date:                         Feb 21, 2024 8:26:31 PM
CVU home:                     /data/u01/app/19c/grid/
User:                         grid
[grid@rac-01 ~]$ 

# 备份响应文件
cp ${GRID_HOME}/install/response/gridsetup.rsp ${GRID_HOME}/install/response/gridsetup.rsp.bak

# 编辑响应文件
vim ${GRID_HOME}/install/response/gridsetup.rsp
------------------------------------------------------
INVENTORY_LOCATION=/data/u01/app/oraInventory
oracle.install.option=CRS_CONFIG
ORACLE_BASE=/data/u01/app/grid
## 添加所需要的组
oracle.install.asm.OSDBA=asmdba
oracle.install.asm.OSOPER=asmoper
oracle.install.asm.OSASM=asmadmin
oracle.install.crs.config.scanType=LOCAL_SCAN
## scan 名，与hosts对应
oracle.install.crs.config.gpnp.scanName=rac-scan
## listener对外服务端口
oracle.install.crs.config.gpnp.scanPort=1521
oracle.install.crs.config.ClusterConfiguration=STANDALONE
oracle.install.crs.config.configureAsExtendedCluster=false
## cluster 名称
oracle.install.crs.config.clusterName=ora19c-cluster
## GNS 此处不开，其对应值空着
oracle.install.crs.config.gpnp.configureGNS=false
oracle.install.crs.config.autoConfigureClusterNodeVIP=false
## 配置网络信息
oracle.install.crs.config.clusterNodes=rac-01:rac-01-vip,rac-02:rac-02-vip
oracle.install.crs.config.networkInterfaceList=eth0:192.168.31.0:1,eth1:10.10.0.0:5
## 配置存储形式
oracle.install.crs.configureGIMR=false
oracle.install.asm.configureGIMRDataDG=false
oracle.install.crs.config.storageOption=FLEX_ASM_STORAGE
## 配置 IPMI
oracle.install.crs.config.useIPMI=false
## 配置ASM
oracle.install.asm.SYSASMPassword=Ninestar123
oracle.install.asm.diskGroup.name=crsdg
oracle.install.asm.diskGroup.redundancy=NORMAL
oracle.install.asm.diskGroup.AUSize=4
oracle.install.asm.diskGroup.disks=/dev/asm_ocr_1,/dev/asm_ocr_2,/dev/asm_ocr_3
oracle.install.asm.diskGroup.diskDiscoveryString=/dev/asm_*
oracle.install.asm.monitorPassword=Ninestar123
oracle.install.crs.configureRHPS=false
oracle.install.crs.config.ignoreDownNodes=false
oracle.install.config.managementOption=NONE
oracle.install.crs.rootconfig.executeRootScript=false
# 升级选项为false，其余选项空着
#oracle.install.crs.upgrade.clusterNodes=
#oracle.install.asm.upgradeASM=false
#oracle.installer.autoupdates.option=SKIP_UPDATES
------------------------------------------------------

# 开始静默安装grid
$GRID_HOME/gridSetup.sh -silent -noconfig  -ignorePrereqFailure  -waitforcompletion -responseFile ${GRID_HOME}/install/response/gridsetup.rsp

# 分别在ora19c-rac1和ora19c-rac2以root用户执行 这里节点有先后顺序，先1后2
/data/u01/app/oraInventory/orainstRoot.sh
/data/u01/app/19c/grid/root.sh

# 继续完成安装配置 仅在 ora19c-rac1 以 grid 用户执行
$GRID_HOME/gridSetup.sh -executeConfigTools -responseFile $GRID_HOME/install/response/gridsetup.rsp -silent

# 分别在ora19c-rac1和ora19c-rac2以root用户执行 这里节点有先后顺序，先1后2
/data/u01/app/19c/grid/root.sh

# 检查
$GRID_HOME/bin/crsctl check cluster -all
$GRID_HOME/bin/crsctl stat res -t
-------------------------------------------------------------------------------
**************************************************************
rac-01:
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online
**************************************************************
rac-02:
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online
**************************************************************
```

注：

* oracle.install.crs.config.clusterName=ora19c-cluster 这个配置的clusterName的值长度要小于等于15，否则后面执行/u01/app/19c/grid/root.sh脚本时会报错**CLSRSC-119: Start of the exclusive mode cluster failed**
* 安装前检查若有失败项，例如：/tmp/shm、DNS、NTP都是可以忽略的。

### 安装 db

```bash
su - oracle
# 上传 LINUX.X64_193000_db_home.zip
rz

# 解压
unzip -d ${ORACLE_HOME}/ LINUX.X64_193000_db_home.zip

# 备份响应文件
cp ${ORACLE_HOME}/install/response/db_install.rsp ${ORACLE_HOME}/install/response/db_install.rsp.bak

# 编辑响应文件
vim ${ORACLE_HOME}/install/response/db_install.rsp
------------------------------------------------------
oracle.install.option=INSTALL_DB_SWONLY
UNIX_GROUP_NAME=oinstall
INVENTORY_LOCATION=/data/u01/app/oraInventory
ORACLE_HOME=/data/u01/app/oracle/product/19c/db_1
ORACLE_BASE=/data/u01/app/oracle
oracle.install.db.InstallEdition=EE
oracle.install.db.OSDBA_GROUP=dba
oracle.install.db.OSOPER_GROUP=oper
oracle.install.db.OSBACKUPDBA_GROUP=backupdba
oracle.install.db.OSDGDBA_GROUP=dgdba
oracle.install.db.OSKMDBA_GROUP=kmdba
oracle.install.db.OSRACDBA_GROUP=dba
oracle.install.db.rootconfig.executeRootScript=false
oracle.install.db.CLUSTER_NODES=rac-01,rac-02
------------------------------------------------------

# 开始静默安装db
$ORACLE_HOME/runInstaller -silent -ignorePrereqFailure  -waitForCompletion -responseFile ${ORACLE_HOME}/install/response/db_install.rsp

# 在ora19c-rac1和ora19c-rac1分别以root用户执行
/data/u01/app/oracle/product/19c/db_1/root.sh

```

### 创建ASM磁盘组

```bash
su - grid

# 创建data
$ORACLE_HOME/bin/asmca -silent -createDiskGroup \
 -sysAsmPassword Ninestar123 \
 -asmsnmpPassword Ninestar123 \
 -diskString '/dev/asm-sd*' \
 -diskGroupName data \
 -diskList '/dev/asm-sdd','/dev/asm-sde' \
 -redundancy EXTERNAL \
 -au_size 4 \
 -compatible.asm 19.0.0.0.0

# 创建arch
$ORACLE_HOME/bin/asmca -silent -createDiskGroup \
 -sysAsmPassword Ninestar123 \
 -asmsnmpPassword Ninestar123 \
 -diskString '/dev/asm-sd*' \
 -diskGroupName arch \
 -diskList '/dev/asm-sdf' \
 -redundancy EXTERNAL \
 -au_size 4 \
 -compatible.asm 19.0.0.0.0

```

### dbca 建库

```bash

su - oracle

# 备份响应文件
cp $ORACLE_HOME/assistants/dbca/dbca.rsp $ORACLE_HOME/assistants/dbca/dbca.rsp.bak

# 编辑响应文件
vim $ORACLE_HOME/assistants/dbca/dbca.rsp
------------------------------------------------------
gdbName=orcl
sid=orcl
databaseConfigType=RAC
policyManaged=FALSE
nodelist=rac-01,rac-02
templateName=General_Purpose.dbc
sysPassword=Ninestar123
systemPassword=Ninestar123
storageType=ASM
diskGroupName=+data
asmsnmpPassword=Ninestar123
characterSet=AL32UTF8
databaseType=MULTIPURPOSE
automaticMemoryManagement=FALSE
totalMemory=4096
------------------------------------------------------
# dbca静默装数据库实例
$ORACLE_HOME/bin/dbca -silent -createDatabase -ignorePreReqs -responseFile $ORACLE_HOME/assistants/dbca/dbca.rsp
```

## 集群验证

### 检查节点应用程序状态

```bash
su - oracle
$ORACLE_HOME/bin/srvctl status nodeapps
```

### 检查节点vip状态及配置

```bash
$ORACLE_HOME/bin/srvctl status vip -n rac-01
$ORACLE_HOME/bin/srvctl config vip -n rac-01
```

### 检查节点监听与监听配置

```bash
$ORACLE_HOME/bin/srvctl status listener

$ORACLE_HOME/bin/srvctl config listener -a
```

### 检查数据库实例状态

```bash
$ORACLE_HOME/bin/srvctl status database -d orcl
```

### 数据库配置

```bash
$ORACLE_HOME/bin/srvctl config database -d orcl -a
```

### asm状态及配置

```bash
$ORACLE_HOME/bin/srvctl status asm

$ORACLE_HOME/bin/srvctl config asm -a
```

### scan状态及配置

```bash
$ORACLE_HOME/bin/srvctl status scan

$ORACLE_HOME/bin/srvctl config scan
```

### 起停监听rac-01

```bash
$ORACLE_HOME/bin/srvctl stop   listener -n rac-01
$ORACLE_HOME/bin/srvctl status listener -n rac-01

$ORACLE_HOME/bin/srvctl start  listener -n rac-01
$ORACLE_HOME/bin/srvctl status listener -n rac-01
```

### 起停实例rac-01

```bash
$ORACLE_HOME/bin/srvctl stop   instance -d orcl -n rac-01
$ORACLE_HOME/bin/srvctl status instance -d orcl -n rac-01

$ORACLE_HOME/bin/srvctl start  instance -d orcl -n rac-01
$ORACLE_HOME/bin/srvctl status instance -d orcl -n rac-01
```

### 

‍
