# 4.Kafka offset

　　日常开发中，相信大家都对 Kafka 有所耳闻，Kafka 作为一个分布式的流处理平台，一般用来存储和传输大量的消息数据。在 Kafka 中有三个重要概念，分别是 topic、partition 和 offset。

* topic 是 kafka 中的消息以主题为单位进行归类的逻辑概念，生产者负责将消息发送到特定的主题，消费者负责订阅主题并进行消费。
* partition 是 topic 的物理概念，每个 topic 可以细分为多个 partition，每个 partition  只属于单个 topic，并且包含不同的消息，partition 用于提高 topic 的存储和消费的性能和可扩展性，可以将 topic  分散在多个 broker 上，并支持多个 consumer 并行消费。
* offset 是 partition 中每条消息的唯一标识，是一个单调递增且不变的值，由 kafka 自动维护，offset 用于定位和记录消息在 partition 中的位置和消费进度，保证 partition 内的消息有序。

　　本文将给大家介绍 offset 的相关概念，**大纲如下**：

* offset 的作用和意义
* offset 的存储和管理
* offset 的提交和重置
* offset 的消费和保证

## offset 的作用和意义

​![](assets/network-asset-9e3553f8-eb6d-4742-9d32-20e98b61725c-20241126164120-r30tgl7.png)​

　　offset 是 Kafka 为每条消息分配的一个唯一的编号，它表示消息在分区中的顺序位置。offset 是从 0 开始的，每当有新的消息写入分区时，offset 就会加 1。offset 是不可变的，即使消息被删除或过期，offset 也不会改变或重用。

　　offset 的作用主要有两个：

* 一是用来定位消息。通过指定 offset，消费者可以准确地找到分区中的某条消息，或者从某个位置开始消费消息。
* 二是用来记录消费进度。消费者在消费完一条消息后，需要提交 offset 来告诉 Kafka broker 自己消费到哪里了。这样，如果消费者发生故障或重启，它可以根据保存的 offset 来恢复消费状态。

## offset 的存储和管理

　　offset 的存储和管理主要涉及到两个方面：生产者端和消费者端。

### 生产者端

　　生产者在向 Kafka 发送消息时，可以指定一个分区键（Partition Key），Kafka 会根据这个键和分区算法来决定消息应该发送到哪个分区。如果没有指定分区键，Kafka 会采用轮询或随机的方式来选择分区。生产者也可以自定义分区算法。

　　当消息被写入到分区后，Kafka broker 会为消息分配一个 offset，并返回给生产者。生产者可以根据返回的 offset 来确认消息是否成功写入，并进行重试或其他处理。

### 消费者端

　　消费者在消费 Kafka 消息时，需要维护一个当前消费的 offset 值，以及一个已提交的 offset 值。当前消费的 offset 值表示消费者正在消费的消息的位置，已提交的 offset 值表示消费者已经确认消费过的消息的位置。

　　消费者在消费完一条消息后，需要提交 offset 来更新已提交的 offset 值。提交 offset 的方式有两种：自动提交和手动提交。

* 自动提交：Kafka 提供了一个配置参数 enable.auto.commit，默认为  true，表示开启自动提交功能。自动提交功能会在后台定期（由 auto.commit.interval.ms 参数控制）将当前消费的  offset 值提交给 Kafka broker。
* 手动提交：如果 enable.auto.commit 设置为 false，则表示关闭自动提交功能，此时消费者需要手动调用  commitSync 或 commitAsync 方法来提交 offset。手动提交功能可以让消费者更灵活地控制何时以及如何提交 offset。

　　无论是自动提交还是手动提交，offset 的实际存储位置都是在 Kafka  的一个内置主题中：\_\_consumer\_offsets。这个主题有 50 个分区（可配置），每个分区存储一部分消费组（Consumer  Group）的 offset 信息。Kafka broker 会根据消费组 ID 和主题名来计算出一个哈希值，并将其映射到  \_\_consumer\_offsets 主题的某个分区上。

　　\_\_consumer\_offsets 主题是 Kafka 0.9.0 版本引入的新特性，之前的版本是将 offset 存储在 Zookeeper 中。但是 Zookeeper 不适合大量写入，因此后来改为存储在 Kafka 自身中，提高了性能和可靠性。

## offset 的提交和重置

　　提交 offset 是消费者在消费完一条消息后，将当前消费的 offset 值更新到 Kafka broker 中的操作。提交 offset 的目的是为了记录消费进度，以便在消费者发生故障或重启时，能够从上次消费的位置继续消费。

　　重置 offset 是消费者在启动或运行过程中，将当前消费的 offset 值修改为其他值的操作。重置 offset 的目的是为了调整消费位置，以便在需要重新消费或跳过某些消息时，能够实现这个需求。

### 提交 offset

　　提交 offset  的方式有两种：自动提交和手动提交。前面已经介绍过这两种方式的区别和用法，这里不再赘述。需要注意的是，无论是自动提交还是手动提交，都不保证提交成功。因为 Kafka broker 可能发生故障或网络延迟，导致提交失败或延迟。因此，消费者需要处理提交失败或延迟的情况。

* 提交失败：如果提交失败，消费者可以选择重试或放弃。重试的话，可能会导致多次提交同一个 offset 值，但是不会影响正确性，因为  Kafka broker 会忽略重复的 offset 值。放弃的话，可能会导致下次启动时重新消费已经消费过的消息，但是不会影响完整性，因为  Kafka 消息是幂等的。
* 提交延迟：如果提交延迟，消费者可以选择等待或继续。等待的话，可能会导致消费速度变慢，或者超过 session.timeout.ms 参数设置的时间而被认为已经死亡。继续的话，可能会导致下次启动时漏掉一些没有提交成功的消息。

### 重置 offset

　　重置 offset 的方式有两种：手动重置和自动重置。手动重置是指消费者主动调用 seek 或 seekToBeginning 或  seekToEnd 方法来修改当前消费的 offset 值。自动重置是指消费者在启动时根据 auto.offset.reset  参数来决定从哪个位置开始消费。

* 手动重置：手动重置可以让消费者精确地控制从哪个位置开始消费。例如，如果想要重新消费某个分区的所有消息，可以调用  seekToBeginning 方法将 offset 设置为 0；如果想要跳过某个分区的所有消息，可以调用 seekToEnd 方法将  offset 设置为最大值；如果想要从某个具体的位置开始消费，可以调用 seek 方法将 offset 设置为任意值。
* 自动重置：自动重置可以让消费者在启动时根据 auto.offset.reset  参数来决定从哪个位置开始消费。auto.offset.reset 参数有三个可选值：earliest, latest 和  none。earliest 表示从最早的可用消息开始消费；latest 表示从最新的可用消息开始消费；none 表示如果没有可用的  offset，则抛出异常。

## offset 的消费和保证

　　offset 的消费和保证主要涉及到两个方面：顺序性和一致性。

### 顺序性

　　顺序性是指 Kafka 消息是否按照发送和接收的顺序进行处理。Kafka 只保证分区内的顺序性，即同一个分区内的消息按照 offset  的顺序进行发送和接收。但是不保证主题内或跨主题的顺序性，即不同分区内的消息可能会乱序发送和接收。因此，如果需要保证主题内或跨主题的顺序性，需要在生产者和消费者端进行额外的处理，例如使用同一个分区键或同一个消费组。

### 一致性

　　一致性是指 Kafka 消息是否能够被正确地发送和接收，不会出现丢失或重复的情况。Kafka 提供了三种不同级别的一致性保证：最多一次（At most once），最少一次（At least once）和精确一次（Exactly once）。

* 最多一次：最多一次是指 Kafka  消息只会被发送或接收一次或零次，不会出现重复的情况，但是可能会出现丢失的情况。这种保证的实现方式是在生产者端关闭重试功能，在消费者端在消费消息之前提交 offset。这种保证适用于对消息丢失不敏感的场景，例如日志收集或监控。
* 最少一次：最少一次是指 Kafka 消息只会被发送或接收一次或多次，不会出现丢失的情况，但是可能会出现重复的情况。这种保证的实现方式是在生产者端开启重试功能，在消费者端在消费消息之后提交 offset。这种保证适用于对消息重复不敏感的场景，例如计数或累加。
* 精确一次：精确一次是指 Kafka 消息只会被发送或接收一次，不会出现丢失或重复的情况。这种保证的实现方式是在生产者端和消费者端使用事务功能，在消费者端使用幂等功能。这种保证适用于对消息丢失和重复都敏感的场景，例如转账或支付。
